{"cells":[{"cell_type":"markdown","metadata":{"id":"punL79CN7Ox6"},"source":["##### Copyright 2020 The TensorFlow Authors."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"_ckMIh7O7s6D"},"outputs":[],"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"Ph5eir3Pf-3z"},"source":["# Constructing a Text Generation Model\n"]},{"cell_type":"markdown","metadata":{"id":"S5Uhzt6vVIB2"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c03_nlp_constructing_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c03_nlp_constructing_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"7GbGfr_oLCat"},"source":["Using most of the techniques you've already learned, it's now possible to generate new text by predicting the next word that follows a given seed word. To practice this method, we'll use the [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics)."]},{"cell_type":"markdown","metadata":{"id":"4aHK2CYygXom"},"source":["## Import TensorFlow and related functions"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"2LmLTREBf5ng","executionInfo":{"status":"ok","timestamp":1679032990115,"user_tz":-420,"elapsed":4155,"user":{"displayName":"Thitiwut Pattanasuttinont","userId":"08829324740535031890"}}},"outputs":[],"source":["import tensorflow as tf\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Other imports for processing data\n","import string\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"GmLTO_dpgge9"},"source":["## Get the Dataset\n","\n","As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"4Bf5FVHfganK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679032997440,"user_tz":-420,"elapsed":7330,"user":{"displayName":"Thitiwut Pattanasuttinont","userId":"08829324740535031890"}},"outputId":"b1fda928-dcf3-46eb-e82b-06a19a7c1019"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-03-17 06:03:09--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n","Resolving drive.google.com (drive.google.com)... 173.194.193.100, 173.194.193.139, 173.194.193.138, ...\n","Connecting to drive.google.com (drive.google.com)|173.194.193.100|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/5rakhl62nehr6v8s0hagr163e2fav7r1/1679032950000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=9d6624b9-141f-404e-9b9d-172b8d8e447b [following]\n","Warning: wildcards not supported in HTTP.\n","--2023-03-17 06:03:15--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/5rakhl62nehr6v8s0hagr163e2fav7r1/1679032950000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=9d6624b9-141f-404e-9b9d-172b8d8e447b\n","Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 172.217.219.132, 2607:f8b0:4001:c13::84\n","Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|172.217.219.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 72436445 (69M) [text/csv]\n","Saving to: ‘/tmp/songdata.csv’\n","\n","/tmp/songdata.csv   100%[===================>]  69.08M  64.6MB/s    in 1.1s    \n","\n","2023-03-17 06:03:16 (64.6 MB/s) - ‘/tmp/songdata.csv’ saved [72436445/72436445]\n","\n"]}],"source":["!wget --no-check-certificate \\\n","    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n","    -O /tmp/songdata.csv"]},{"cell_type":"markdown","metadata":{"id":"gu1BTzMIS1oy"},"source":["## **First 10 Songs**\n","\n","Let's first look at just 10 songs from the dataset, and see how things perform."]},{"cell_type":"markdown","metadata":{"id":"fmb9rGaAUDO-"},"source":["### Preprocessing\n","\n","Let's perform some basic preprocessing to get rid of punctuation and make everything lowercase. We'll then split the lyrics up by line and tokenize the lyrics."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"2AVAvyF_Vuh5","executionInfo":{"status":"ok","timestamp":1679032997440,"user_tz":-420,"elapsed":6,"user":{"displayName":"Thitiwut Pattanasuttinont","userId":"08829324740535031890"}}},"outputs":[],"source":["def tokenize_corpus(corpus, num_words=-1):\n","  # Fit a Tokenizer on the corpus\n","  if num_words > -1:\n","    tokenizer = Tokenizer(num_words=num_words)\n","  else:\n","    tokenizer = Tokenizer()\n","  tokenizer.fit_on_texts(corpus)\n","  return tokenizer\n","\n","def create_lyrics_corpus(dataset, field):\n","  # Remove all other punctuation\n","  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n","  # Make it lowercase\n","  dataset[field] = dataset[field].str.lower()\n","  # Make it one long string to split by line\n","  lyrics = dataset[field].str.cat()\n","  corpus = lyrics.split('\\n')\n","  # Remove any trailing whitespace\n","  for l in range(len(corpus)):\n","    corpus[l] = corpus[l].rstrip()\n","  # Remove any empty lines\n","  corpus = [l for l in corpus if l != '']\n","\n","  return corpus"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"apcEXp7WhVBs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679033000396,"user_tz":-420,"elapsed":2959,"user":{"displayName":"Thitiwut Pattanasuttinont","userId":"08829324740535031890"}},"outputId":"b229e485-00fa-4ee3-e278-81e0d9866c43"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'you': 1, 'i': 2, 'and': 3, 'a': 4, 'me': 5, 'the': 6, 'is': 7, 'my': 8, 'to': 9, 'ma': 10, 'it': 11, 'of': 12, 'im': 13, 'your': 14, 'love': 15, 'so': 16, 'as': 17, 'that': 18, 'in': 19, 'andante': 20, 'boomaboomerang': 21, 'make': 22, 'on': 23, 'oh': 24, 'for': 25, 'but': 26, 'new': 27, 'bang': 28, 'its': 29, 'be': 30, 'like': 31, 'know': 32, 'now': 33, 'how': 34, 'could': 35, 'youre': 36, 'sing': 37, 'never': 38, 'no': 39, 'chiquitita': 40, 'can': 41, 'we': 42, 'song': 43, 'had': 44, 'good': 45, 'youll': 46, 'she': 47, 'just': 48, 'girl': 49, 'again': 50, 'will': 51, 'take': 52, 'please': 53, 'let': 54, 'am': 55, 'eyes': 56, 'was': 57, 'always': 58, 'cassandra': 59, 'blue': 60, 'time': 61, 'dont': 62, 'were': 63, 'return': 64, 'once': 65, 'then': 66, 'sorry': 67, 'cryin': 68, 'over': 69, 'feel': 70, 'ever': 71, 'believe': 72, 'what': 73, 'do': 74, 'go': 75, 'all': 76, 'out': 77, 'think': 78, 'every': 79, 'leave': 80, 'look': 81, 'at': 82, 'way': 83, 'one': 84, 'music': 85, 'down': 86, 'our': 87, 'give': 88, 'learn': 89, 'more': 90, 'us': 91, 'would': 92, 'there': 93, 'before': 94, 'when': 95, 'with': 96, 'feeling': 97, 'play': 98, 'cause': 99, 'away': 100, 'here': 101, 'have': 102, 'yes': 103, 'baby': 104, 'get': 105, 'didnt': 106, 'see': 107, 'did': 108, 'closed': 109, 'realized': 110, 'crazy': 111, 'world': 112, 'lord': 113, 'shes': 114, 'kind': 115, 'without': 116, 'if': 117, 'touch': 118, 'strong': 119, 'making': 120, 'such': 121, 'found': 122, 'true': 123, 'stay': 124, 'together': 125, 'thought': 126, 'come': 127, 'they': 128, 'sweet': 129, 'tender': 130, 'sender': 131, 'tune': 132, 'humdehumhum': 133, 'gonna': 134, 'last': 135, 'leaving': 136, 'sleep': 137, 'only': 138, 'saw': 139, 'tell': 140, 'hes': 141, 'her': 142, 'sound': 143, 'tread': 144, 'lightly': 145, 'ground': 146, 'ill': 147, 'show': 148, 'life': 149, 'too': 150, 'used': 151, 'darling': 152, 'meant': 153, 'break': 154, 'end': 155, 'yourself': 156, 'little': 157, 'dumbedumdum': 158, 'bedumbedumdum': 159, 'youve': 160, 'dumbbedumbdumb': 161, 'bedumbbedumbdumb': 162, 'by': 163, 'theyre': 164, 'alone': 165, 'misunderstood': 166, 'day': 167, 'dawning': 168, 'some': 169, 'wanted': 170, 'none': 171, 'listen': 172, 'words': 173, 'warning': 174, 'darkest': 175, 'nights': 176, 'nobody': 177, 'knew': 178, 'fight': 179, 'caught': 180, 'really': 181, 'power': 182, 'dreams': 183, 'weave': 184, 'until': 185, 'final': 186, 'hour': 187, 'morning': 188, 'ship': 189, 'gone': 190, 'grieving': 191, 'still': 192, 'pain': 193, 'cry': 194, 'sun': 195, 'try': 196, 'face': 197, 'something': 198, 'sees': 199, 'makes': 200, 'fine': 201, 'who': 202, 'mine': 203, 'leaves': 204, 'walk': 205, 'hand': 206, 'well': 207, 'about': 208, 'things': 209, 'slow': 210, 'theres': 211, 'talk': 212, 'why': 213, 'up': 214, 'lousy': 215, 'packing': 216, 'ive': 217, 'gotta': 218, 'near': 219, 'keeping': 220, 'intention': 221, 'growing': 222, 'taking': 223, 'dimension': 224, 'even': 225, 'better': 226, 'thank': 227, 'god': 228, 'not': 229, 'somebody': 230, 'happy': 231, 'question': 232, 'smile': 233, 'mean': 234, 'much': 235, 'kisses': 236, 'around': 237, 'anywhere': 238, 'advice': 239, 'care': 240, 'use': 241, 'selfish': 242, 'tool': 243, 'fool': 244, 'showing': 245, 'boomerang': 246, 'throwing': 247, 'warm': 248, 'kiss': 249, 'surrender': 250, 'giving': 251, 'been': 252, 'door': 253, 'burning': 254, 'bridges': 255, 'being': 256, 'moving': 257, 'though': 258, 'behind': 259, 'are': 260, 'must': 261, 'sure': 262, 'stood': 263, 'hope': 264, 'this': 265, 'deny': 266, 'sad': 267, 'quiet': 268, 'truth': 269, 'heartaches': 270, 'scars': 271, 'dancing': 272, 'sky': 273, 'shining': 274, 'above': 275, 'hear': 276, 'came': 277, 'couldnt': 278, 'everything': 279, 'back': 280, 'long': 281, 'waitin': 282, 'cold': 283, 'chills': 284, 'bone': 285, 'youd': 286, 'wonderful': 287, 'means': 288, 'special': 289, 'smiles': 290, 'lucky': 291, 'fellow': 292, 'park': 293, 'holds': 294, 'squeezes': 295, 'walking': 296, 'hours': 297, 'talking': 298, 'plan': 299, 'easy': 300, 'gently': 301, 'summer': 302, 'evening': 303, 'breeze': 304, 'grow': 305, 'fingers': 306, 'soft': 307, 'light': 308, 'body': 309, 'velvet': 310, 'night': 311, 'soul': 312, 'slowly': 313, 'shimmer': 314, 'thousand': 315, 'butterflies': 316, 'float': 317, 'put': 318, 'rotten': 319, 'boy': 320, 'tough': 321, 'stuff': 322, 'saying': 323, 'need': 324, 'anymore': 325, 'enough': 326, 'standing': 327, 'creep': 328, 'felt': 329, 'cheap': 330, 'notion': 331, 'deep': 332, 'dumb': 333, 'mistake': 334, 'entitled': 335, 'another': 336, 'beg': 337, 'forgive': 338, 'an': 339, 'feels': 340, 'hoot': 341, 'holler': 342, 'mad': 343, 'under': 344, 'heel': 345, 'holy': 346, 'christ': 347, 'deal': 348, 'sick': 349, 'tired': 350, 'tedious': 351, 'ways': 352, 'aint': 353, 'walkin': 354, 'cutting': 355, 'tie': 356, 'wanna': 357, 'into': 358, 'eye': 359, 'myself': 360, 'counting': 361, 'pride': 362, 'unright': 363, 'neighbours': 364, 'ride': 365, 'burying': 366, 'past': 367, 'peace': 368, 'free': 369, 'sucker': 370, 'street': 371, 'singing': 372, 'shouting': 373, 'staying': 374, 'alive': 375, 'city': 376, 'dead': 377, 'hiding': 378, 'their': 379, 'shame': 380, 'hollow': 381, 'laughter': 382, 'while': 383, 'crying': 384, 'bed': 385, 'pity': 386, 'believed': 387, 'lost': 388, 'from': 389, 'start': 390, 'suffer': 391, 'sell': 392, 'secrets': 393, 'bargain': 394, 'playing': 395, 'smart': 396, 'aching': 397, 'hearts': 398, 'sailing': 399, 'father': 400, 'sister': 401, 'reason': 402, 'linger': 403, 'deeply': 404, 'future': 405, 'casting': 406, 'shadow': 407, 'else': 408, 'fate': 409, 'bags': 410, 'thorough': 411, 'knowing': 412, 'late': 413, 'wait': 414, 'watched': 415, 'harbor': 416, 'sunrise': 417, 'sails': 418, 'almost': 419, 'slack': 420, 'cool': 421, 'rain': 422, 'deck': 423, 'tiny': 424, 'figure': 425, 'rigid': 426, 'restrained': 427, 'filled': 428, 'whats': 429, 'wrong': 430, 'enchained': 431, 'own': 432, 'sorrow': 433, 'tomorrow': 434, 'hate': 435, 'shoulder': 436, 'best': 437, 'friend': 438, 'rely': 439, 'broken': 440, 'feather': 441, 'patch': 442, 'walls': 443, 'tumbling': 444, 'loves': 445, 'blown': 446, 'candle': 447, 'seems': 448, 'hard': 449, 'handle': 450, 'id': 451, 'thinking': 452, 'went': 453, 'house': 454, 'hardly': 455, 'guy': 456, 'closing': 457, 'front': 458, 'emptiness': 459, 'he': 460, 'disapeared': 461, 'his': 462, 'car': 463, 'stunned': 464, 'dreamed': 465, 'lifes': 466, 'part': 467, 'move': 468, 'feet': 469, 'pavement': 470, 'acted': 471, 'told': 472, 'lies': 473, 'meet': 474, 'other': 475, 'guys': 476, 'stupid': 477, 'blind': 478, 'smiled': 479, 'took': 480, 'said': 481, 'may': 482, 'couple': 483, 'men': 484, 'them': 485, 'brother': 486, 'joe': 487, 'seeing': 488, 'lot': 489, 'him': 490, 'nice': 491, 'sitting': 492, 'sittin': 493, 'memories': 494}\n","495\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-3-fbdddccf8583>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n","  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n"]}],"source":["# Read the dataset from csv - just first 10 songs for now\n","dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:10]\n","# Create the corpus using the 'text' column containing lyrics\n","corpus = create_lyrics_corpus(dataset, 'text')\n","# Tokenize the corpus\n","tokenizer = tokenize_corpus(corpus)\n","\n","total_words = len(tokenizer.word_index) + 1\n","\n","print(tokenizer.word_index)\n","print(total_words)"]},{"cell_type":"markdown","metadata":{"id":"v9x68iN_X6FK"},"source":["### Create Sequences and Labels\n","\n","After preprocessing, we next need to create sequences and labels. Creating the sequences themselves is similar to before with `texts_to_sequences`, but also including the use of [N-Grams](https://towardsdatascience.com/introduction-to-language-models-n-gram-e323081503d9); creating the labels will now utilize those sequences as well as utilize one-hot encoding over all potential output words."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"QmlTsUqfikVO","executionInfo":{"status":"ok","timestamp":1679033003508,"user_tz":-420,"elapsed":867,"user":{"displayName":"Thitiwut Pattanasuttinont","userId":"08829324740535031890"}}},"outputs":[],"source":["sequences = []\n","for line in corpus:\n","\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n","\tfor i in range(1, len(token_list)):\n","\t\tn_gram_sequence = token_list[:i+1]\n","\t\tsequences.append(n_gram_sequence)\n","\n","# Pad sequences for equal input length \n","max_sequence_len = max([len(seq) for seq in sequences])\n","sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n","\n","# Split sequences between the \"input\" sequence and \"output\" predicted word\n","input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n","# One-hot encode the labels\n","one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Zsmu3aEId49i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679033006153,"user_tz":-420,"elapsed":4,"user":{"displayName":"Thitiwut Pattanasuttinont","userId":"08829324740535031890"}},"outputId":"11118f33-c12a-451c-904a-34c4b7472d1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["32\n","97\n","[  0   0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29\n","   4]\n","[  0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29   4\n"," 287]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"]}],"source":["# Check out how some of our data is being stored\n","# The Tokenizer has just a single index per word\n","print(tokenizer.word_index['know'])\n","print(tokenizer.word_index['feeling'])\n","# Input sequences will have multiple indexes\n","print(input_sequences[5])\n","print(input_sequences[6])\n","# And the one hot labels will be as long as the full spread of tokenized words\n","print(one_hot_labels[5])\n","print(one_hot_labels[6])"]},{"cell_type":"markdown","metadata":{"id":"-1TAJMlmfO8r"},"source":["### Train a Text Generation Model\n","\n","Building an RNN to train our text generation model will be very similar to the sentiment models you've built previously. The only real change necessary is to make sure to use Categorical instead of Binary Cross Entropy as the loss function - we could use Binary before since the sentiment was only 0 or 1, but now there are hundreds of categories.\n","\n","From there, we should also consider using *more* epochs than before, as text generation can take a little longer to converge than sentiment analysis, *and* we aren't working with all that much data yet. I'll set it at 200 epochs here since we're only use part of the dataset, and training will tail off quite a bit over that many epochs."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"G1YXuxIqfygN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679033163077,"user_tz":-420,"elapsed":149455,"user":{"displayName":"Thitiwut Pattanasuttinont","userId":"08829324740535031890"}},"outputId":"3181a3c0-abdb-44a4-b9da-f74a137e06a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","62/62 [==============================] - 13s 74ms/step - loss: 6.0440 - accuracy: 0.0237\n","Epoch 2/200\n","62/62 [==============================] - 1s 22ms/step - loss: 5.4578 - accuracy: 0.0358\n","Epoch 3/200\n","62/62 [==============================] - 1s 12ms/step - loss: 5.3670 - accuracy: 0.0409\n","Epoch 4/200\n","62/62 [==============================] - 1s 12ms/step - loss: 5.3079 - accuracy: 0.0444\n","Epoch 5/200\n","62/62 [==============================] - 0s 7ms/step - loss: 5.2308 - accuracy: 0.0499\n","Epoch 6/200\n","62/62 [==============================] - 1s 16ms/step - loss: 5.1588 - accuracy: 0.0494\n","Epoch 7/200\n","62/62 [==============================] - 1s 12ms/step - loss: 5.0961 - accuracy: 0.0550\n","Epoch 8/200\n","62/62 [==============================] - 1s 10ms/step - loss: 5.0375 - accuracy: 0.0595\n","Epoch 9/200\n","62/62 [==============================] - 1s 13ms/step - loss: 4.9791 - accuracy: 0.0626\n","Epoch 10/200\n","62/62 [==============================] - 1s 10ms/step - loss: 4.9132 - accuracy: 0.0600\n","Epoch 11/200\n","62/62 [==============================] - 0s 7ms/step - loss: 4.8345 - accuracy: 0.0686\n","Epoch 12/200\n","62/62 [==============================] - 0s 7ms/step - loss: 4.7487 - accuracy: 0.0792\n","Epoch 13/200\n","62/62 [==============================] - 1s 10ms/step - loss: 4.6616 - accuracy: 0.0853\n","Epoch 14/200\n","62/62 [==============================] - 1s 10ms/step - loss: 4.5608 - accuracy: 0.0898\n","Epoch 15/200\n","62/62 [==============================] - 1s 9ms/step - loss: 4.4684 - accuracy: 0.0979\n","Epoch 16/200\n","62/62 [==============================] - 0s 7ms/step - loss: 4.3720 - accuracy: 0.1271\n","Epoch 17/200\n","62/62 [==============================] - 0s 7ms/step - loss: 4.2709 - accuracy: 0.1393\n","Epoch 18/200\n","62/62 [==============================] - 0s 7ms/step - loss: 4.1673 - accuracy: 0.1529\n","Epoch 19/200\n","62/62 [==============================] - 0s 7ms/step - loss: 4.0761 - accuracy: 0.1630\n","Epoch 20/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.9802 - accuracy: 0.1857\n","Epoch 21/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.8981 - accuracy: 0.1988\n","Epoch 22/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.8057 - accuracy: 0.2170\n","Epoch 23/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.7351 - accuracy: 0.2250\n","Epoch 24/200\n","62/62 [==============================] - 1s 9ms/step - loss: 3.6666 - accuracy: 0.2311\n","Epoch 25/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.5871 - accuracy: 0.2487\n","Epoch 26/200\n","62/62 [==============================] - 0s 7ms/step - loss: 3.5079 - accuracy: 0.2745\n","Epoch 27/200\n","62/62 [==============================] - 1s 9ms/step - loss: 3.4235 - accuracy: 0.2952\n","Epoch 28/200\n","62/62 [==============================] - 1s 9ms/step - loss: 3.3509 - accuracy: 0.3027\n","Epoch 29/200\n","62/62 [==============================] - 1s 9ms/step - loss: 3.2779 - accuracy: 0.3239\n","Epoch 30/200\n","62/62 [==============================] - 1s 9ms/step - loss: 3.2144 - accuracy: 0.3426\n","Epoch 31/200\n","62/62 [==============================] - 1s 9ms/step - loss: 3.1517 - accuracy: 0.3527\n","Epoch 32/200\n","62/62 [==============================] - 1s 9ms/step - loss: 3.0972 - accuracy: 0.3673\n","Epoch 33/200\n","62/62 [==============================] - 1s 9ms/step - loss: 3.0358 - accuracy: 0.3845\n","Epoch 34/200\n","62/62 [==============================] - 1s 10ms/step - loss: 2.9699 - accuracy: 0.3935\n","Epoch 35/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.9049 - accuracy: 0.4067\n","Epoch 36/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.8588 - accuracy: 0.4147\n","Epoch 37/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.8174 - accuracy: 0.4183\n","Epoch 38/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.7856 - accuracy: 0.4218\n","Epoch 39/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.7270 - accuracy: 0.4369\n","Epoch 40/200\n","62/62 [==============================] - 1s 9ms/step - loss: 2.6574 - accuracy: 0.4606\n","Epoch 41/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.6033 - accuracy: 0.4717\n","Epoch 42/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.5488 - accuracy: 0.4793\n","Epoch 43/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.5019 - accuracy: 0.4854\n","Epoch 44/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.4551 - accuracy: 0.4945\n","Epoch 45/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.4149 - accuracy: 0.5020\n","Epoch 46/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.3709 - accuracy: 0.5136\n","Epoch 47/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.3339 - accuracy: 0.5126\n","Epoch 48/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.2873 - accuracy: 0.5212\n","Epoch 49/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.2510 - accuracy: 0.5343\n","Epoch 50/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.2072 - accuracy: 0.5373\n","Epoch 51/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.1712 - accuracy: 0.5530\n","Epoch 52/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.1506 - accuracy: 0.5499\n","Epoch 53/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.1095 - accuracy: 0.5590\n","Epoch 54/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.0755 - accuracy: 0.5676\n","Epoch 55/200\n","62/62 [==============================] - 0s 7ms/step - loss: 2.0420 - accuracy: 0.5716\n","Epoch 56/200\n","62/62 [==============================] - 1s 10ms/step - loss: 1.9986 - accuracy: 0.5792\n","Epoch 57/200\n","62/62 [==============================] - 1s 10ms/step - loss: 1.9604 - accuracy: 0.5908\n","Epoch 58/200\n","62/62 [==============================] - 1s 14ms/step - loss: 1.9282 - accuracy: 0.5933\n","Epoch 59/200\n","62/62 [==============================] - 1s 11ms/step - loss: 1.9040 - accuracy: 0.6120\n","Epoch 60/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.8860 - accuracy: 0.6054\n","Epoch 61/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.8548 - accuracy: 0.6226\n","Epoch 62/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.8236 - accuracy: 0.6282\n","Epoch 63/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.7847 - accuracy: 0.6362\n","Epoch 64/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.7548 - accuracy: 0.6393\n","Epoch 65/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.7265 - accuracy: 0.6423\n","Epoch 66/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.7072 - accuracy: 0.6524\n","Epoch 67/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.6657 - accuracy: 0.6650\n","Epoch 68/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.6481 - accuracy: 0.6650\n","Epoch 69/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.6271 - accuracy: 0.6736\n","Epoch 70/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.5868 - accuracy: 0.6796\n","Epoch 71/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.5625 - accuracy: 0.6867\n","Epoch 72/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.5428 - accuracy: 0.6927\n","Epoch 73/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.5150 - accuracy: 0.6958\n","Epoch 74/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.4838 - accuracy: 0.6932\n","Epoch 75/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.4612 - accuracy: 0.7074\n","Epoch 76/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.4416 - accuracy: 0.7059\n","Epoch 77/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.4176 - accuracy: 0.7159\n","Epoch 78/200\n","62/62 [==============================] - 1s 9ms/step - loss: 1.4100 - accuracy: 0.7129\n","Epoch 79/200\n","62/62 [==============================] - 1s 9ms/step - loss: 1.3888 - accuracy: 0.7159\n","Epoch 80/200\n","62/62 [==============================] - 1s 10ms/step - loss: 1.3593 - accuracy: 0.7255\n","Epoch 81/200\n","62/62 [==============================] - 1s 12ms/step - loss: 1.3458 - accuracy: 0.7326\n","Epoch 82/200\n","62/62 [==============================] - 1s 9ms/step - loss: 1.3401 - accuracy: 0.7250\n","Epoch 83/200\n","62/62 [==============================] - 1s 10ms/step - loss: 1.3162 - accuracy: 0.7361\n","Epoch 84/200\n","62/62 [==============================] - 1s 11ms/step - loss: 1.2969 - accuracy: 0.7361\n","Epoch 85/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.2941 - accuracy: 0.7407\n","Epoch 86/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.2699 - accuracy: 0.7457\n","Epoch 87/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.2436 - accuracy: 0.7477\n","Epoch 88/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.2185 - accuracy: 0.7533\n","Epoch 89/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.1924 - accuracy: 0.7684\n","Epoch 90/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.1749 - accuracy: 0.7598\n","Epoch 91/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.1602 - accuracy: 0.7629\n","Epoch 92/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.1484 - accuracy: 0.7750\n","Epoch 93/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.1293 - accuracy: 0.7730\n","Epoch 94/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.1108 - accuracy: 0.7760\n","Epoch 95/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.1048 - accuracy: 0.7805\n","Epoch 96/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.0932 - accuracy: 0.7785\n","Epoch 97/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.0730 - accuracy: 0.7805\n","Epoch 98/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.0570 - accuracy: 0.7866\n","Epoch 99/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.0395 - accuracy: 0.7891\n","Epoch 100/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.0269 - accuracy: 0.7982\n","Epoch 101/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.0078 - accuracy: 0.7972\n","Epoch 102/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.0780 - accuracy: 0.7760\n","Epoch 103/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.0668 - accuracy: 0.7760\n","Epoch 104/200\n","62/62 [==============================] - 0s 7ms/step - loss: 1.0240 - accuracy: 0.7916\n","Epoch 105/200\n","62/62 [==============================] - 0s 8ms/step - loss: 0.9967 - accuracy: 0.7952\n","Epoch 106/200\n","62/62 [==============================] - 1s 9ms/step - loss: 0.9648 - accuracy: 0.7992\n","Epoch 107/200\n","62/62 [==============================] - 1s 10ms/step - loss: 0.9434 - accuracy: 0.8093\n","Epoch 108/200\n","62/62 [==============================] - 1s 11ms/step - loss: 0.9252 - accuracy: 0.8123\n","Epoch 109/200\n","62/62 [==============================] - 1s 10ms/step - loss: 0.9085 - accuracy: 0.8138\n","Epoch 110/200\n","62/62 [==============================] - 0s 8ms/step - loss: 0.8948 - accuracy: 0.8179\n","Epoch 111/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.8828 - accuracy: 0.8184\n","Epoch 112/200\n","62/62 [==============================] - 1s 11ms/step - loss: 0.8720 - accuracy: 0.8189\n","Epoch 113/200\n","62/62 [==============================] - 0s 8ms/step - loss: 0.8577 - accuracy: 0.8229\n","Epoch 114/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.8462 - accuracy: 0.8239\n","Epoch 115/200\n","62/62 [==============================] - 1s 10ms/step - loss: 0.8370 - accuracy: 0.8224\n","Epoch 116/200\n","62/62 [==============================] - 0s 8ms/step - loss: 0.8392 - accuracy: 0.8259\n","Epoch 117/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.8288 - accuracy: 0.8244\n","Epoch 118/200\n","62/62 [==============================] - 0s 8ms/step - loss: 0.8228 - accuracy: 0.8239\n","Epoch 119/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.8251 - accuracy: 0.8234\n","Epoch 120/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.8196 - accuracy: 0.8224\n","Epoch 121/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.8901 - accuracy: 0.8052\n","Epoch 122/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.8199 - accuracy: 0.8259\n","Epoch 123/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.8053 - accuracy: 0.8244\n","Epoch 124/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7785 - accuracy: 0.8345\n","Epoch 125/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7568 - accuracy: 0.8335\n","Epoch 126/200\n","62/62 [==============================] - 1s 10ms/step - loss: 0.7425 - accuracy: 0.8396\n","Epoch 127/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7326 - accuracy: 0.8441\n","Epoch 128/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7361 - accuracy: 0.8385\n","Epoch 129/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7254 - accuracy: 0.8476\n","Epoch 130/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.7101 - accuracy: 0.8481\n","Epoch 131/200\n","62/62 [==============================] - 1s 10ms/step - loss: 0.6991 - accuracy: 0.8491\n","Epoch 132/200\n","62/62 [==============================] - 1s 11ms/step - loss: 0.6906 - accuracy: 0.8522\n","Epoch 133/200\n","62/62 [==============================] - 1s 11ms/step - loss: 0.6824 - accuracy: 0.8557\n","Epoch 134/200\n","62/62 [==============================] - 1s 8ms/step - loss: 0.6790 - accuracy: 0.8567\n","Epoch 135/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6704 - accuracy: 0.8572\n","Epoch 136/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6626 - accuracy: 0.8542\n","Epoch 137/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6560 - accuracy: 0.8582\n","Epoch 138/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6513 - accuracy: 0.8618\n","Epoch 139/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6447 - accuracy: 0.8633\n","Epoch 140/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6437 - accuracy: 0.8592\n","Epoch 141/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6347 - accuracy: 0.8638\n","Epoch 142/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6237 - accuracy: 0.8658\n","Epoch 143/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6244 - accuracy: 0.8592\n","Epoch 144/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6268 - accuracy: 0.8673\n","Epoch 145/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6237 - accuracy: 0.8683\n","Epoch 146/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6149 - accuracy: 0.8678\n","Epoch 147/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5961 - accuracy: 0.8718\n","Epoch 148/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5915 - accuracy: 0.8653\n","Epoch 149/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5805 - accuracy: 0.8703\n","Epoch 150/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5721 - accuracy: 0.8749\n","Epoch 151/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5653 - accuracy: 0.8784\n","Epoch 152/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5615 - accuracy: 0.8784\n","Epoch 153/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6111 - accuracy: 0.8643\n","Epoch 154/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.6548 - accuracy: 0.8577\n","Epoch 155/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5975 - accuracy: 0.8688\n","Epoch 156/200\n","62/62 [==============================] - 1s 8ms/step - loss: 0.5705 - accuracy: 0.8764\n","Epoch 157/200\n","62/62 [==============================] - 1s 10ms/step - loss: 0.5550 - accuracy: 0.8734\n","Epoch 158/200\n","62/62 [==============================] - 1s 10ms/step - loss: 0.5415 - accuracy: 0.8764\n","Epoch 159/200\n","62/62 [==============================] - 1s 10ms/step - loss: 0.5343 - accuracy: 0.8774\n","Epoch 160/200\n","62/62 [==============================] - 0s 8ms/step - loss: 0.5305 - accuracy: 0.8829\n","Epoch 161/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5213 - accuracy: 0.8860\n","Epoch 162/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5134 - accuracy: 0.8824\n","Epoch 163/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5087 - accuracy: 0.8819\n","Epoch 164/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.5026 - accuracy: 0.8840\n","Epoch 165/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4981 - accuracy: 0.8870\n","Epoch 166/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4956 - accuracy: 0.8855\n","Epoch 167/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4924 - accuracy: 0.8905\n","Epoch 168/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4870 - accuracy: 0.8865\n","Epoch 169/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4803 - accuracy: 0.8860\n","Epoch 170/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4749 - accuracy: 0.8870\n","Epoch 171/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4703 - accuracy: 0.8915\n","Epoch 172/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4664 - accuracy: 0.8895\n","Epoch 173/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4612 - accuracy: 0.8880\n","Epoch 174/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4579 - accuracy: 0.8895\n","Epoch 175/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4534 - accuracy: 0.8900\n","Epoch 176/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4577 - accuracy: 0.8865\n","Epoch 177/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4539 - accuracy: 0.8885\n","Epoch 178/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4450 - accuracy: 0.8895\n","Epoch 179/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4434 - accuracy: 0.8870\n","Epoch 180/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4374 - accuracy: 0.8900\n","Epoch 181/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4572 - accuracy: 0.8865\n","Epoch 182/200\n","62/62 [==============================] - 1s 11ms/step - loss: 0.4548 - accuracy: 0.8845\n","Epoch 183/200\n","62/62 [==============================] - 1s 9ms/step - loss: 0.4499 - accuracy: 0.8880\n","Epoch 184/200\n","62/62 [==============================] - 1s 11ms/step - loss: 0.4420 - accuracy: 0.8946\n","Epoch 185/200\n","62/62 [==============================] - 1s 8ms/step - loss: 0.4727 - accuracy: 0.8814\n","Epoch 186/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4385 - accuracy: 0.8890\n","Epoch 187/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4224 - accuracy: 0.8925\n","Epoch 188/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8951\n","Epoch 189/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8961\n","Epoch 190/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4037 - accuracy: 0.8971\n","Epoch 191/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.3999 - accuracy: 0.8930\n","Epoch 192/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.8971\n","Epoch 193/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.8951\n","Epoch 194/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.3913 - accuracy: 0.8991\n","Epoch 195/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.3877 - accuracy: 0.8966\n","Epoch 196/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.3923 - accuracy: 0.8976\n","Epoch 197/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4024 - accuracy: 0.8956\n","Epoch 198/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.8835\n","Epoch 199/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.8880\n","Epoch 200/200\n","62/62 [==============================] - 0s 7ms/step - loss: 0.4265 - accuracy: 0.8880\n"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n","\n","model = Sequential()\n","model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n","model.add(Bidirectional(LSTM(20)))\n","model.add(Dense(total_words, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","history = model.fit(input_sequences, one_hot_labels, epochs=200, verbose=1)"]},{"cell_type":"markdown","metadata":{"id":"AXVFpoREhV6Y"},"source":["### View the Training Graph"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"aeSNfS7uhch0","colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"status":"ok","timestamp":1679033163078,"user_tz":-420,"elapsed":7,"user":{"displayName":"Thitiwut Pattanasuttinont","userId":"08829324740535031890"}},"outputId":"fb6abb7d-2a32-4c1e-a188-45b409ea8b66"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["import matplotlib.pyplot as plt\n","\n","def plot_graphs(history, string):\n","  plt.plot(history.history[string])\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(string)\n","  plt.show()\n","\n","plot_graphs(history, 'accuracy')"]},{"cell_type":"markdown","metadata":{"id":"1rAgRpxYhjpB"},"source":["### Generate new lyrics!\n","\n","It's finally time to generate some new lyrics from the trained model, and see what we get. To do so, we'll provide some \"seed text\", or an input sequence for the model to start with. We'll also decide just how long of an output sequence we want - this could essentially be infinite, as the input plus the previous output will be continuously fed in for a new output word (at least up to our max sequence length)."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"DC7zfcgviDTp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679033188911,"user_tz":-420,"elapsed":6613,"user":{"displayName":"Thitiwut Pattanasuttinont","userId":"08829324740535031890"}},"outputId":"6c3cdadd-c4e2-4d8a-b42c-39a2ff778d21"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 667ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","im feeling chills me to and you like it me strong be pain tool heel heel fate fate am you know stood will be heel gonna cassandra bang true song chiquitita tell it mean will take a summer evening breeze is about would before about be about be learn learn bang slowly of mean yourself feeling would and would weave over would weave over would weave weave scars over would me did fate pain laughter heel heel fate fate found will song chiquitita and you know will and is a break it thorough break break break door father song chiquitita and no long\n"]}],"source":["seed_text = \"im feeling chills\"\n","next_words = 100\n","  \n","for _ in range(next_words):\n","\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n","\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n","\toutput_word = \"\"\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == predicted:\n","\t\t\toutput_word = word\n","\t\t\tbreak\n","\tseed_text += \" \" + output_word\n","print(seed_text)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c03_nlp_constructing_text_generation_model.ipynb","timestamp":1679032649187}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}